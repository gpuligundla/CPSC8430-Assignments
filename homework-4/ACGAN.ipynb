{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "291090b1-ab55-4556-8959-f2ab3319f05e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torchvision.utils as utils\n",
    "import matplotlib.animation as animation\n",
    "from torch.autograd import Variable\n",
    "import time\n",
    "from torch.utils.data import Subset\n",
    "import torchvision.models as models\n",
    "import torch.nn.functional as F\n",
    "from scipy import linalg\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b859ee11-d48b-4ebe-bfde-aff54bc525db",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01a5cde6-6683-4aa8-abe3-7e6b88e7063b",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b0ef702-ab9e-4ea6-9abd-56dbbcd2343c",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = torchvision.transforms.Compose([\n",
    "        torchvision.transforms.ToTensor(), \n",
    "        torchvision.transforms.Resize(32), \n",
    "        torchvision.transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "dataset = datasets.CIFAR10(\"./cifar10\", download=True, train=True, transform=transform)\n",
    "\n",
    "data_loader = torch.utils.data.DataLoader(dataset, batch_size=64, shuffle=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e15b53d-fb90-4751-9a97-6d9123f2c0fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_image_batch = next(iter(data_loader))\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Real Images\")\n",
    "plt.imshow(np.transpose(utils.make_grid(real_image_batch[0].to(device), padding=2, normalize=True).cpu(), (1, 2, 0)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b963c04b-c2ef-4d6f-b03f-2cd149b99ba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "        self.emb = nn.Embedding(10, 100)\n",
    "        self.fc = nn.Linear(100 + 100, 128 * 8 * 8)\n",
    "        self.main = nn.Sequential(\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.Conv2d(128, 128, 3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(128, 0.8),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(128, 64, 3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(64, 0.8),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(64, 3, 3, stride=1, padding=1),\n",
    "            nn.Tanh(),\n",
    "        )\n",
    "\n",
    "    def forward(self, noise, labels):\n",
    "        x = torch.cat((self.emb(labels), noise), dim=1)\n",
    "        x = self.fc(x)\n",
    "        x = x.view(x.size(0), 128, 8, 8)\n",
    "        x = self.main(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ef3521f-c566-4292-9050-e9aa29f89ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.feature_extractor = nn.Sequential(\n",
    "            nn.Conv2d(3, 16, kernel_size=3, stride=2, padding=1),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(16, 32, kernel_size=3, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(32, 0.8),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(32, 64, kernel_size=3, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(64, 0.8),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(64, 128, kernel_size=3, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(128, 0.8),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "        )\n",
    "        self.validity_layer = nn.Sequential(nn.Linear(128 * 2 * 2, 1), nn.Sigmoid())\n",
    "        self.label_layer = nn.Sequential(nn.Linear(128 * 2 * 2, 10), nn.Softmax(dim=1))\n",
    "\n",
    "    def forward(self, img):\n",
    "        features = self.feature_extractor(img)\n",
    "        features = features.view(features.size(0), -1)\n",
    "        validity = self.validity_layer(features)\n",
    "        label = self.label_layer(features)\n",
    "        return validity, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a20441ba-9728-430d-a36c-b3c7723ab937",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_weights(model):\n",
    "    for m in model.modules():\n",
    "        if isinstance(m, nn.Conv2d) or isinstance(m, nn.ConvTranspose2d):\n",
    "            nn.init.normal_(m.weight, 0.0, 0.02)\n",
    "        elif isinstance(m, nn.BatchNorm2d):\n",
    "            nn.init.normal_(m.weight, 1.0, 0.02)\n",
    "            nn.init.constant_(m.bias, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3693992-7762-41cf-9d82-5d38d28fc789",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = Generator().to(device)\n",
    "discriminator = Discriminator().to(device)\n",
    "\n",
    "initialize_weights(generator)\n",
    "initialize_weights(discriminator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b5a36c2-715d-445a-91bb-aaaaf38de2ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('Results/ACGAN_FAKE'):\n",
    "    os.makedirs('Results/ACGAN_FAKE')\n",
    "if not os.path.exists('Results/ACGAN_REAL'):\n",
    "    os.makedirs('Results/ACGAN_REAL')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b957d433-7f7f-4b3f-97be-0eaadc71c62d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class InceptionV3(nn.Module):\n",
    "    \"\"\"Pretrained InceptionV3 network returning feature maps\"\"\"\n",
    "\n",
    "    # Index of default block of inception to return,\n",
    "    # corresponds to output of final average pooling\n",
    "    DEFAULT_BLOCK_INDEX = 3\n",
    "\n",
    "    # Maps feature dimensionality to their output blocks indices\n",
    "    BLOCK_INDEX_BY_DIM = {\n",
    "        64: 0,   # First max pooling features\n",
    "        192: 1,  # Second max pooling featurs\n",
    "        768: 2,  # Pre-aux classifier features\n",
    "        2048: 3  # Final average pooling features\n",
    "    }\n",
    "\n",
    "    def __init__(self,\n",
    "                 output_blocks=[DEFAULT_BLOCK_INDEX],\n",
    "                 resize_input=True,\n",
    "                 normalize_input=True,\n",
    "                 requires_grad=False):\n",
    "        \n",
    "        super(InceptionV3, self).__init__()\n",
    "\n",
    "        self.resize_input = resize_input\n",
    "        self.normalize_input = normalize_input\n",
    "        self.output_blocks = sorted(output_blocks)\n",
    "        self.last_needed_block = max(output_blocks)\n",
    "\n",
    "        assert self.last_needed_block <= 3, \\\n",
    "            'Last possible output block index is 3'\n",
    "\n",
    "        self.blocks = nn.ModuleList()\n",
    "\n",
    "        \n",
    "        inception = models.inception_v3(pretrained=True)\n",
    "\n",
    "        # Block 0: input to maxpool1\n",
    "        block0 = [\n",
    "            inception.Conv2d_1a_3x3,\n",
    "            inception.Conv2d_2a_3x3,\n",
    "            inception.Conv2d_2b_3x3,\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2)\n",
    "        ]\n",
    "        self.blocks.append(nn.Sequential(*block0))\n",
    "\n",
    "        # Block 1: maxpool1 to maxpool2\n",
    "        if self.last_needed_block >= 1:\n",
    "            block1 = [\n",
    "                inception.Conv2d_3b_1x1,\n",
    "                inception.Conv2d_4a_3x3,\n",
    "                nn.MaxPool2d(kernel_size=3, stride=2)\n",
    "            ]\n",
    "            self.blocks.append(nn.Sequential(*block1))\n",
    "\n",
    "        # Block 2: maxpool2 to aux classifier\n",
    "        if self.last_needed_block >= 2:\n",
    "            block2 = [\n",
    "                inception.Mixed_5b,\n",
    "                inception.Mixed_5c,\n",
    "                inception.Mixed_5d,\n",
    "                inception.Mixed_6a,\n",
    "                inception.Mixed_6b,\n",
    "                inception.Mixed_6c,\n",
    "                inception.Mixed_6d,\n",
    "                inception.Mixed_6e,\n",
    "            ]\n",
    "            self.blocks.append(nn.Sequential(*block2))\n",
    "\n",
    "        # Block 3: aux classifier to final avgpool\n",
    "        if self.last_needed_block >= 3:\n",
    "            block3 = [\n",
    "                inception.Mixed_7a,\n",
    "                inception.Mixed_7b,\n",
    "                inception.Mixed_7c,\n",
    "                nn.AdaptiveAvgPool2d(output_size=(1, 1))\n",
    "            ]\n",
    "            self.blocks.append(nn.Sequential(*block3))\n",
    "\n",
    "        for param in self.parameters():\n",
    "            param.requires_grad = requires_grad\n",
    "\n",
    "    def forward(self, inp):\n",
    "        outp = []\n",
    "        x = inp\n",
    "\n",
    "        if self.resize_input:\n",
    "            x = F.interpolate(x,\n",
    "                              size=(299, 299),\n",
    "                              mode='bilinear',\n",
    "                              align_corners=False)\n",
    "\n",
    "        if self.normalize_input:\n",
    "            x = 2 * x - 1  # Scale from range (0, 1) to range (-1, 1)\n",
    "\n",
    "        for idx, block in enumerate(self.blocks):\n",
    "            x = block(x)\n",
    "            if idx in self.output_blocks:\n",
    "                outp.append(x)\n",
    "\n",
    "            if idx == self.last_needed_block:\n",
    "                break\n",
    "\n",
    "        return outp\n",
    "    \n",
    "block_idx = InceptionV3.BLOCK_INDEX_BY_DIM[2048]\n",
    "inception_model = InceptionV3([block_idx])\n",
    "inception_model = inception_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12a95b72-ef8e-40d6-a736-304c18cb4b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_activation_statistics(images,model,batch_size=128, dims=2048,\n",
    "                    cuda=False):\n",
    "    model.eval()\n",
    "    act=np.empty((len(images), dims))\n",
    "    \n",
    "    if cuda:\n",
    "        batch=images.cuda()\n",
    "    else:\n",
    "        batch=images\n",
    "    pred = model(batch)[0]\n",
    "    if pred.size(2) != 1 or pred.size(3) != 1:\n",
    "        pred = adaptive_avg_pool2d(pred, output_size=(1, 1))\n",
    "\n",
    "    act= pred.cpu().data.numpy().reshape(pred.size(0), -1)\n",
    "    \n",
    "    mu = np.mean(act, axis=0)\n",
    "    sigma = np.cov(act, rowvar=False)\n",
    "    return mu, sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93dade0e-f23f-4927-8d67-f17daeb8aafd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_frechet_distance(mu1, sigma1, mu2, sigma2, eps=1e-6):\n",
    "    mu1 = np.atleast_1d(mu1)\n",
    "    mu2 = np.atleast_1d(mu2)\n",
    "\n",
    "    sigma1 = np.atleast_2d(sigma1)\n",
    "    sigma2 = np.atleast_2d(sigma2)\n",
    "\n",
    "    assert mu1.shape == mu2.shape, \\\n",
    "        'Training and test mean vectors have different lengths'\n",
    "    assert sigma1.shape == sigma2.shape, \\\n",
    "        'Training and test covariances have different dimensions'\n",
    "\n",
    "    diff = mu1 - mu2\n",
    "\n",
    "    \n",
    "    covmean, _ = linalg.sqrtm(sigma1.dot(sigma2), disp=False)\n",
    "    if not np.isfinite(covmean).all():\n",
    "        msg = ('fid calculation produces singular product; '\n",
    "               'adding %s to diagonal of cov estimates') % eps\n",
    "        print(msg)\n",
    "        offset = np.eye(sigma1.shape[0]) * eps\n",
    "        covmean = linalg.sqrtm((sigma1 + offset).dot(sigma2 + offset))\n",
    "\n",
    "    \n",
    "    if np.iscomplexobj(covmean):\n",
    "        if not np.allclose(np.diagonal(covmean).imag, 0, atol=1e-3):\n",
    "            m = np.max(np.abs(covmean.imag))\n",
    "            raise ValueError('Imaginary component {}'.format(m))\n",
    "        covmean = covmean.real\n",
    "\n",
    "    tr_covmean = np.trace(covmean)\n",
    "\n",
    "    return (diff.dot(diff) + np.trace(sigma1) +\n",
    "            np.trace(sigma2) - 2 * tr_covmean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0a58b22-2242-4068-a0d4-38e3d237a616",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_fretchet(images_real,images_fake,model):\n",
    "    mu_1,std_1=calculate_activation_statistics(images_real,model,cuda=True)\n",
    "    mu_2,std_2=calculate_activation_statistics(images_fake,model,cuda=True)\n",
    "    fid_value = calculate_frechet_distance(mu_1, std_1, mu_2, std_2)\n",
    "    return fid_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e64c77f-9fe8-4ac4-b7bd-4f8325213fc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_loss_arr = []\n",
    "disc_loss_arr = []\n",
    "fake_image = []\n",
    "real_image = []\n",
    "FID_arr = []\n",
    "\n",
    "def train(generator, discriminator, dataloader, epochs):    \n",
    "    optimG = optim.Adam(generator.parameters(), lr=0.0002, betas=(0.5,0.999))\n",
    "    optimD = optim.Adam(discriminator.parameters(), lr=0.0002, betas=(0.5,0.999))\n",
    "    source_criterion = nn.BCELoss()\n",
    "    class_criterion = nn.NLLLoss()\n",
    "    \n",
    "    generator.train()\n",
    "    discriminator.train()\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        \n",
    "        batch_gen_loss = []\n",
    "        batch_disc_loss = []\n",
    "        real_images = None\n",
    "        fake_images = None\n",
    "        \n",
    "        for idx, (real_images, real_labels) in enumerate(dataloader, 0):\n",
    "            real_labels = real_labels.to(device)\n",
    "            real_images = real_images.to(device)\n",
    "            batch_size = real_images.size(0)\n",
    "            \n",
    "            fake = torch.zeros(batch_size).to(device)\n",
    "            valid = torch.ones(batch_size).to(device)\n",
    "                    \n",
    "            optimD.zero_grad()\n",
    "            z = Variable(torch.cuda.FloatTensor(np.random.normal(0, 1, (batch_size, 100))))\n",
    "            generated_labels = Variable(torch.cuda.LongTensor(np.random.randint(0, 10, batch_size)))\n",
    "            generated_images = generator(z, generated_labels)\n",
    "            real_pred, real_aux = discriminator(real_images)\n",
    "            disc_loss_real = 0.5 * (source_criterion(real_pred, valid.unsqueeze(1)) + class_criterion(real_aux, real_labels))\n",
    "            \n",
    "            fake_pred, fake_aux = discriminator(generated_images.detach())\n",
    "            disc_loss_fake = 0.5 * (source_criterion(fake_pred, fake.unsqueeze(1)) + class_criterion(fake_aux, generated_labels))\n",
    "            disc_loss = 0.5 * (disc_loss_real + disc_loss_fake)\n",
    "            disc_loss.backward()\n",
    "            optimD.step()\n",
    "            batch_disc_loss.append(disc_loss.item())    \n",
    "            \n",
    "            optimG.zero_grad()  \n",
    "            validity, predicted_label = discriminator(generated_images)\n",
    "            gen_loss = 0.5 * (source_criterion(validity, valid.unsqueeze(1)) + class_criterion(predicted_label, generated_labels))\n",
    "            gen_loss.backward()\n",
    "            optimG.step()\n",
    "            batch_gen_loss.append(gen_loss.item())\n",
    "            \n",
    "        \n",
    "            if idx % 100 == 0 or epoch==epochs:\n",
    "                print(f\"Epoch [{epoch}/{epochs}], Step [{idx}/{len(dataloader)}], \"\n",
    "                      f\"Discriminator Loss: {disc_loss.item()}, Generator Loss: {gen_loss.item()}\")\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            z = Variable(torch.cuda.FloatTensor(np.random.normal(0, 1, (batch_size, 100))))\n",
    "            generated_labels = Variable(torch.cuda.LongTensor(np.random.randint(0, 10, batch_size)))\n",
    "            fake_images = generator(z, generated_labels)\n",
    "            fakeimg_grid = torchvision.utils.make_grid(fake_images.detach().cpu(), padding=2, normalize=True)\n",
    "            real_images_grid = torchvision.utils.make_grid(real_images.detach().cpu(), padding=2, normalize=True)\n",
    "            fake_image.append(fakeimg_grid)\n",
    "            real_image.append(real_images_grid)\n",
    "            #Save images\n",
    "            utils.save_image(fakeimg_grid,'./Results/ACGAN_FAKE/ACGAN_epoch_%03d.png' % (epoch), normalize = True)\n",
    "            utils.save_image(real_images_grid,'./Results/ACGAN_REAL/ACGAN_epoch_%03d.png' % (epoch), normalize = True)\n",
    "            \n",
    "        gen_loss_arr.append(np.mean(batch_gen_loss))\n",
    "        disc_loss_arr.append(np.mean(batch_disc_loss))\n",
    "        \n",
    "        #Cal FID\n",
    "        fretchet_dist=calculate_fretchet(real_images, fake_images, inception_model)\n",
    "        FID_arr.append(fretchet_dist)\n",
    "        print(f\"FID value at epoch{epoch}/{epochs} is {fretchet_dist}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcb62fb7-5474-4790-b2b1-780bab65c4ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "train(generator, discriminator, data_loader, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7f91791-e0c7-470d-95a2-b0bf687b484a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('Results/FID'):\n",
    "       os.makedirs('Results/FID')\n",
    "np.save('Results/ACGAN_FID', FID_arr) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8652f59-b73f-41be-aef0-f7b232ed5cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "plt.title(\"Generator and Discriminator Loss During Training\")\n",
    "plt.plot(gen_loss_arr, label=\"Generator Loss\")\n",
    "plt.plot(disc_loss_arr, label=\"Discriminator Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a559dd8-8d4a-4065-8551-17427f44c217",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "plt.title(\"FID Score During Training\")\n",
    "plt.plot(FID_arr, label=\"FID Score\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"FID Score\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1373ec37-f124-4128-a879-a6b367bcb68c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#real\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Real Images\")\n",
    "plt.imshow(np.transpose(utils.make_grid(real_image[-1], padding=2, normalize=True).cpu(), (1, 2, 0)))\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# fake \n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Fake Images\")\n",
    "plt.imshow(np.transpose(utils.make_grid(fake_image[-1], padding=2, normalize=True).cpu(), (1, 2, 0)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c7f67b8-d4e1-4b6b-a500-2653770116fc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
