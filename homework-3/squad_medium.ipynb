{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "2abec2df-e29e-4ea3-89d8-932c63380dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import transformers\n",
    "from evaluate import load\n",
    "from transformers import BertTokenizerFast, AdamW, BertForQuestionAnswering, get_scheduler\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim.lr_scheduler import ExponentialLR\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "72f62c14-e661-499d-bc3c-9a741de6a57b",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "fd315ccb-e395-4b93-8289-aaf297c584ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_PATH = \"/scratch/gpuligu/Spoken-SQuAD-master\"\n",
    "\n",
    "spoken_train = \"spoken_train-v1.1.json\"\n",
    "spoken_test = \"spoken_test-v1.1.json\"\n",
    "spoken_test_WER44 = \"spoken_test-v1.1_WER44.json\"\n",
    "spoken_test_WER54 = \"spoken_test-v1.1_WER54.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "37323fb5-6f64-4538-832c-609e953a8f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_json_data(path):\n",
    "    contexts = []\n",
    "    questions = []\n",
    "    answers = []\n",
    "    \n",
    "    with open(path, 'rb') as file:\n",
    "        raw_data = json.load(file)\n",
    "\n",
    "    for group in raw_data['data']:\n",
    "        for paragraph in group['paragraphs']:\n",
    "            context = paragraph['context']\n",
    "            for qa in paragraph['qas']:\n",
    "                question = qa['question']\n",
    "                for answer in qa['answers']:\n",
    "                    contexts.append(context.lower())\n",
    "                    questions.append(question.lower())\n",
    "                    answers.append(answer)\n",
    "\n",
    "    return contexts, questions, answers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a59a681b-957c-4a8e-a058-d8bb4ee6e610",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "1567f5a7-2e2a-4ed0-942f-39f44af6949d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data: what is in front of the notre dame main building?, {'answer_start': 187, 'text': 'a copper statue of christ'}\n",
      "Testing Data: which nfl team represented the afc at super bowl 50?, {'answer_start': 190, 'text': 'denver broncos'}\n",
      "Testing Data_44: which nfl team represented the afc at super bowl 50?, {'answer_start': 177, 'text': 'Denver Broncos'}\n",
      "Testing Data_54: which nfl team represented the afc at super bowl 50?, {'answer_start': 177, 'text': 'Denver Broncos'}\n"
     ]
    }
   ],
   "source": [
    "train_data_path = os.path.join(BASE_PATH, spoken_train) \n",
    "test_data_path = os.path.join(BASE_PATH, spoken_test)\n",
    "test_data_path_WER44 = os.path.join(BASE_PATH, spoken_test_WER44)\n",
    "test_data_path_WER54 = os.path.join(BASE_PATH, spoken_test_WER54)\n",
    "\n",
    "\n",
    "# loading training data\n",
    "train_contexts, train_questions, train_answers = read_json_data(train_data_path)\n",
    "print(f\"Training Data: {train_questions[0]}, {train_answers[0]}\")\n",
    "\n",
    "# loading testing data\n",
    "valid_contexts, valid_questions, valid_answers = read_json_data(test_data_path)\n",
    "print(f\"Testing Data: {valid_questions[0]}, {valid_answers[0]}\")\n",
    "\n",
    "# loading testing WER 44 data\n",
    "valid_contexts_44, valid_questions_44, valid_answers_44 = read_json_data(test_data_path_WER44)\n",
    "print(f\"Testing Data_44: {valid_questions_44[0]}, {valid_answers_44[0]}\")\n",
    "\n",
    "# loading testing WER 54 data\n",
    "valid_contexts_54, valid_questions_54, valid_answers_54 = read_json_data(test_data_path_WER54)\n",
    "print(f\"Testing Data_54: {valid_questions_54[0]}, {valid_answers_54[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "fdab46ba-009d-44ad-a3de-bbe8a54453e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_answer_end_index(answers, contexts):\n",
    "    for answer, context in zip(answers, contexts):\n",
    "        expected_answer = answer['text']\n",
    "        start_idx = answer['answer_start']\n",
    "        end_idx = start_idx + len(expected_answer)\n",
    "\n",
    "        if context[start_idx:end_idx] == expected_answer:\n",
    "            answer['answer_end'] = end_idx\n",
    "        else:\n",
    "            for offset in [1, 2]:\n",
    "                if context[start_idx - offset:end_idx - offset] == expected_answer:\n",
    "                    answer['answer_start'] = start_idx - offset\n",
    "                    answer['answer_end'] = end_idx - offset\n",
    "                    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "5cecec81-de62-4341-bb40-0d9e42a29645",
   "metadata": {},
   "outputs": [],
   "source": [
    "add_answer_end_index(train_answers, train_contexts)\n",
    "add_answer_end_index(valid_answers, valid_contexts)\n",
    "add_answer_end_index(valid_answers_44, valid_contexts_44)\n",
    "add_answer_end_index(valid_answers_44, valid_contexts_44)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "34dff04f-7206-4f70-81df-0d57ec3b572f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_contexts_trunc = []\n",
    "MAX_LENGTH = 512\n",
    "\n",
    "for i in range(len(train_contexts)):\n",
    "    if len(train_contexts[i]) > MAX_LENGTH:\n",
    "        answer_start = train_answers[i]['answer_start']\n",
    "        answer_end = train_answers[i]['answer_start'] + len(train_answers[i]['text'])\n",
    "        mid = (answer_start + answer_end) // 2\n",
    "        para_start = max(0, min(mid - MAX_LENGTH // 2, len(train_contexts[i]) - MAX_LENGTH))\n",
    "        para_end = para_start + MAX_LENGTH\n",
    "        train_contexts_trunc.append(train_contexts[i][para_start:para_end])\n",
    "        train_answers[i]['answer_start'] = max(0, ((MAX_LENGTH // 2) - len(train_answers[i]['text'])))\n",
    "\n",
    "    else:\n",
    "        train_contexts_trunc.append(train_contexts[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "76a833d5-a729-408a-97ec-4009eb94d1ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LENGTH = 512\n",
    "MODEL = \"bert-base-uncased\"\n",
    "doc_stride = 128\n",
    "\n",
    "# initialize the tokenizer\n",
    "tokenizerFast = BertTokenizerFast.from_pretrained(MODEL)\n",
    "\n",
    "# tokenize\n",
    "train_encodings = tokenizerFast(train_questions, train_contexts, max_length=MAX_LENGTH, truncation=True, padding=True, stride=doc_stride)\n",
    "valid_encodings = tokenizerFast(valid_questions,valid_contexts, max_length=MAX_LENGTH, truncation=True, padding=True, stride=doc_stride)\n",
    "valid_encodings_44 = tokenizerFast(valid_questions_44,valid_contexts_44, max_length=MAX_LENGTH, truncation=True, padding=True, stride=doc_stride)\n",
    "valid_encodings_54 = tokenizerFast(valid_questions_54,valid_contexts_54, max_length=MAX_LENGTH, truncation=True, padding=True, stride=doc_stride)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "b60d1b65-822e-4c9c-8aab-bdf3a670ae74",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_answer_positions(encodings, answers, tokenizer):\n",
    "    start_positions = []\n",
    "    end_positions = []\n",
    "\n",
    "    for idx in range(len(encodings['input_ids'])):\n",
    "        answer_text = answers[idx]['text']\n",
    "        answer_encoding = tokenizer(answer_text, max_length=MAX_LENGTH, truncation=True, padding=True)\n",
    "\n",
    "        found_start = False\n",
    "        for a in range(len(encodings['input_ids'][idx]) - len(answer_encoding['input_ids'])):\n",
    "            match = True\n",
    "            for i in range(1, len(answer_encoding['input_ids'])-1):\n",
    "                if answer_encoding['input_ids'][i] != encodings['input_ids'][idx][a + i]:\n",
    "                    match = False\n",
    "                    break\n",
    "            if match:\n",
    "                start_positions.append(a)\n",
    "                end_positions.append(a + len(answer_encoding['input_ids']) - 1)\n",
    "                found_start = True\n",
    "                break\n",
    "        if not found_start:\n",
    "            start_positions.append(0)\n",
    "            end_positions.append(0)\n",
    "\n",
    "    return start_positions, end_positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "951f3a82-f6e1-47e7-aefe-916c2525e39c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update train encodings with start and end positions\n",
    "train_start_positions, train_end_positions = find_answer_positions(train_encodings, train_answers, tokenizerFast)\n",
    "train_encodings.update({'start_positions': train_start_positions, 'end_positions': train_end_positions})\n",
    "\n",
    "# Update test encodings with start and end positions\n",
    "valid_start_positions, valid_end_positions = find_answer_positions(valid_encodings, valid_answers, tokenizerFast)\n",
    "valid_encodings.update({'start_positions': valid_start_positions, 'end_positions': valid_end_positions})\n",
    "\n",
    "# Update test 44 encodings with start and end positions\n",
    "valid_start_positions_44, valid_end_positions_44 = find_answer_positions(valid_encodings_44, valid_answers_44, tokenizerFast)\n",
    "valid_encodings_44.update({'start_positions': valid_start_positions_44, 'end_positions': valid_end_positions_44})\n",
    "\n",
    "# Update test 54 encodings with start and end positions\n",
    "valid_start_positions_54, valid_end_positions_54 = find_answer_positions(valid_encodings_54, valid_answers_54, tokenizerFast)\n",
    "valid_encodings_54.update({'start_positions': valid_start_positions_54, 'end_positions': valid_end_positions_54})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "f8b98590-dc34-4382-9bbd-beb53f970bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SquadDataset(Dataset):\n",
    "    def __init__(self, encodings):\n",
    "        self.input_ids = torch.tensor(encodings['input_ids'])\n",
    "        self.token_type_ids = torch.tensor(encodings['token_type_ids'])\n",
    "        self.attention_mask = torch.tensor(encodings['attention_mask'])\n",
    "        self.start_positions = torch.tensor(encodings['start_positions'])\n",
    "        self.end_positions = torch.tensor(encodings['end_positions'])\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            'input_ids': self.input_ids[idx],\n",
    "            'token_type_ids': self.token_type_ids[idx],\n",
    "            'attention_mask': self.attention_mask[idx],\n",
    "            'start_positions': self.start_positions[idx],\n",
    "            'end_positions': self.end_positions[idx]\n",
    "        }\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.input_ids)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "4fd33aa1-b2d7-498b-9d93-47d7cdc02f34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build datasets\n",
    "train_dataset = SquadDataset(train_encodings)\n",
    "valid_dataset = SquadDataset(valid_encodings)\n",
    "valid_dataset_44 = SquadDataset(valid_encodings_44)\n",
    "valid_dataset_54 = SquadDataset(valid_encodings_54)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "83ec0541-e9e7-4da8-b13d-6f084f7783c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForQuestionAnswering were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BertForQuestionAnswering(\n",
      "  (bert): BertModel(\n",
      "    (embeddings): BertEmbeddings(\n",
      "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
      "      (position_embeddings): Embedding(512, 768)\n",
      "      (token_type_embeddings): Embedding(2, 768)\n",
      "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (encoder): BertEncoder(\n",
      "      (layer): ModuleList(\n",
      "        (0-11): 12 x BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (qa_outputs): Linear(in_features=768, out_features=2, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Load the pre-trained model\n",
    "model = BertForQuestionAnswering.from_pretrained('bert-base-uncased')\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "2a7d9bcb-4edd-497f-a546-2f717e7dab19",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_dataloader, num_epochs=1):\n",
    "    model.to(device)\n",
    "    model.train()\n",
    "    \n",
    "    optimizer = AdamW(model.parameters(), lr=2e-5, weight_decay=2e-2)\n",
    "    training_steps = num_epochs * len(train_dataloader)\n",
    "    lr_scheduler = get_scheduler(\n",
    "        \"linear\",\n",
    "        optimizer=optimizer,\n",
    "        num_warmup_steps=0,\n",
    "        num_training_steps=training_steps,\n",
    "    )\n",
    "    \n",
    "    loss_arr = []\n",
    "    acc_arr = []\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        losses = []\n",
    "        accuracies = []\n",
    "        with tqdm(train_dataloader, desc=f'Epoch {epoch+1}') as t:\n",
    "            \n",
    "            for batch in t:\n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "                input_ids = batch['input_ids'].to(device)\n",
    "                attention_mask = batch['attention_mask'].to(device)\n",
    "                token_type_ids = batch['token_type_ids'].to(device)\n",
    "                start_positions = batch['start_positions'].to(device)\n",
    "                end_positions = batch['end_positions'].to(device)\n",
    "                \n",
    "                outputs = model(input_ids, attention_mask=attention_mask,\n",
    "                                start_positions=start_positions,\n",
    "                                token_type_ids=token_type_ids,\n",
    "                                end_positions=end_positions)\n",
    "                \n",
    "                loss = outputs[0]\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                lr_scheduler.step()\n",
    "                \n",
    "                # Calculate accuracy\n",
    "                start_logits, end_logits = outputs[1], outputs[2]\n",
    "                start_pred = start_logits.argmax(dim=1)\n",
    "                end_pred = end_logits.argmax(dim=1)\n",
    "                acc = ((start_pred == start_positions).float().mean() + \n",
    "                       (end_pred == end_positions).float().mean()) / 2\n",
    "                \n",
    "                losses.append(loss.item())\n",
    "                accuracies.append(acc.item())\n",
    "                \n",
    "                t.set_postfix_str(f'Loss: {loss.item():.4f}, Acc: {acc.item():.4f}')\n",
    "            \n",
    "        loss_arr.append(np.mean(losses))\n",
    "        acc_arr.append(np.mean(accuracies))\n",
    "    \n",
    "    return loss_arr, acc_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "3290a13c-d792-4deb-8d06-a7864d2db476",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gpuligu/.local/lib/python3.9/site-packages/transformers/optimization.py:429: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Epoch 1:   2%|‚ñè         | 55/2320 [00:26<18:10,  2.08it/s, Loss: 4.1377, Acc: 0.0312]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [73]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m train_data_loader \u001b[38;5;241m=\u001b[39m DataLoader(train_dataset, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m16\u001b[39m, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m----> 2\u001b[0m loss_arr, acc_arr \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_data_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [72]\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(model, train_dataloader, num_epochs)\u001b[0m\n\u001b[1;32m     36\u001b[0m loss \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     37\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m---> 38\u001b[0m \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     39\u001b[0m lr_scheduler\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     41\u001b[0m \u001b[38;5;66;03m# Calculate accuracy\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:75\u001b[0m, in \u001b[0;36mLRScheduler.__init__.<locals>.with_counter.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     73\u001b[0m instance\u001b[38;5;241m.\u001b[39m_step_count \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     74\u001b[0m wrapped \u001b[38;5;241m=\u001b[39m func\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__get__\u001b[39m(instance, \u001b[38;5;28mcls\u001b[39m)\n\u001b[0;32m---> 75\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/torch/optim/optimizer.py:385\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    380\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    381\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    382\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    383\u001b[0m             )\n\u001b[0;32m--> 385\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    386\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer_step_code()\n\u001b[1;32m    388\u001b[0m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/transformers/optimization.py:485\u001b[0m, in \u001b[0;36mAdamW.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    482\u001b[0m \u001b[38;5;66;03m# Decay the first and second moment running average coefficient\u001b[39;00m\n\u001b[1;32m    483\u001b[0m \u001b[38;5;66;03m# In-place operations to update the averages at the same time\u001b[39;00m\n\u001b[1;32m    484\u001b[0m exp_avg\u001b[38;5;241m.\u001b[39mmul_(beta1)\u001b[38;5;241m.\u001b[39madd_(grad, alpha\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m1.0\u001b[39m \u001b[38;5;241m-\u001b[39m beta1))\n\u001b[0;32m--> 485\u001b[0m \u001b[43mexp_avg_sq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmul_\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbeta2\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maddcmul_\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgrad\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1.0\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    486\u001b[0m denom \u001b[38;5;241m=\u001b[39m exp_avg_sq\u001b[38;5;241m.\u001b[39msqrt()\u001b[38;5;241m.\u001b[39madd_(group[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124meps\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m    488\u001b[0m step_size \u001b[38;5;241m=\u001b[39m group[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlr\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_data_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "loss_arr, acc_arr = train_model(model, train_data_loader, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "28896c7f-a9f9-446a-a99b-e7ee012fc311",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "def calculate_f1_score(predictions, references):\n",
    "    f1_scores = []\n",
    "    for pred, ref in zip(predictions, references):\n",
    "        common = Counter(pred) & Counter(ref)\n",
    "        num_same = sum(common.values())\n",
    "        if num_same == 0:\n",
    "            f1_scores.append(0)\n",
    "            continue\n",
    "        precision = num_same / len(pred)\n",
    "        recall = num_same / len(ref)\n",
    "        f1 = (2 * precision * recall) / (precision + recall)\n",
    "        f1_scores.append(f1)\n",
    "    avg_f1_score = sum(f1_scores) / len(f1_scores)\n",
    "    return avg_f1_score\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "d70bf28b-3598-4d48-bb30-2c6c1060f0bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score on Test Data: 0.7542423885356532\n",
      "F1 Score on Test Data 44: 0.42468614972543284\n",
      "F1 Score on Test Data 54: 0.3041936139479789\n"
     ]
    }
   ],
   "source": [
    "max_answer_length=30\n",
    "\n",
    "def evaluate_model(model, test_dataloader):\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    references = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in test_dataloader:\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            token_type_ids = batch['token_type_ids'].to(device)\n",
    "            start_positions = batch['start_positions'].to(device)\n",
    "            end_positions = batch['end_positions'].to(device)\n",
    "\n",
    "            outputs = model(input_ids, attention_mask=attention_mask,\n",
    "                            start_positions=start_positions,\n",
    "                            token_type_ids=token_type_ids,\n",
    "                            end_positions=end_positions)\n",
    "\n",
    "            start_logits, end_logits = outputs.start_logits, outputs.end_logits\n",
    "            start_pred = torch.argmax(start_logits, dim=1)\n",
    "            end_pred = torch.argmax(end_logits, dim=1)\n",
    "\n",
    "            for i in range(len(start_pred)):\n",
    "                start = start_pred[i].item()\n",
    "                end = end_pred[i].item()\n",
    "                \n",
    "                # Skip answers where start index > end index or length is greater than max_answer_length\n",
    "                if start > end or end - start + 1 > max_answer_length:\n",
    "                    predicted_answer = \"\"\n",
    "                else:\n",
    "                    predicted_answer = tokenizerFast.decode(batch['input_ids'][i][start:end+1], skip_special_tokens=True)\n",
    "                \n",
    "                predictions.append(predicted_answer)\n",
    "\n",
    "                reference_start = batch['start_positions'][i].item()\n",
    "                reference_end = batch['end_positions'][i].item()\n",
    "                reference_answer = tokenizerFast.decode(batch['input_ids'][i][reference_start:reference_end+1], skip_special_tokens=True)\n",
    "                references.append(reference_answer)\n",
    "            \n",
    "    avg_f1_score = calculate_f1_score(predictions, references)\n",
    "    return avg_f1_score\n",
    "\n",
    "\n",
    "\n",
    "valid_data_loader = DataLoader(valid_dataset, batch_size=16)\n",
    "valid_data_loader_44 = DataLoader(valid_dataset_44, batch_size=16)\n",
    "valid_data_loader_54 = DataLoader(valid_dataset_54, batch_size=16)\n",
    "\n",
    "f1_score = evaluate_model(model, valid_data_loader)\n",
    "print(f\"F1 Score on Test Data: {f1_score}\")\n",
    "\n",
    "f1_score = evaluate_model(model, valid_data_loader_44)\n",
    "print(f\"F1 Score on Test Data 44: {f1_score}\")\n",
    "\n",
    "f1_score = evaluate_model(model, valid_data_loader_54)\n",
    "print(f\"F1 Score on Test Data 54: {f1_score}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53d771f3-9a60-4116-8ebb-f8ea1c024a27",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89740df0-97b4-4a6b-989e-efdc973bdfd3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "417dbedc-286a-4037-80b5-d0655a8ad1bf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
